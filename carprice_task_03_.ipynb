{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se1nINwRHz_7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***EXPLORE THE DATA***"
      ],
      "metadata": {
        "id": "fVZiyqcPDaIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/car data.csv')"
      ],
      "metadata": {
        "id": "NPsPS8KkCogy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# statistical summary of data\n",
        "num_sum = data.describe()\n",
        "palette = sns.color_palette('inferno', as_cmap=True)\n",
        "num_sum.style.background_gradient(cmap=palette)"
      ],
      "metadata": {
        "id": "omBCr_XE7xma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "L5iMACYn3zn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of data\n",
        "data.shape"
      ],
      "metadata": {
        "id": "5Te91HZi5WYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***DATA CLEANING***"
      ],
      "metadata": {
        "id": "wa_OMGkhGEpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# missing values\n",
        "missing = data.isnull().sum()\n",
        "print(missing)\n",
        "\n",
        "# Check if there are any missing values\n",
        "if missing.any():\n",
        "    print(\"\\nMissing values found in the dataset:\")\n",
        "    print(missing[missing > 0])  # Display only columns with missing values\n",
        "else:\n",
        "    print('\\nThere are no missing values in the dataset')"
      ],
      "metadata": {
        "id": "zZQ_nsolGKTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns that are not useful for modeling\n",
        "data.drop(['Owner'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Se7n5rjVuWA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# info of data\n",
        "data.info()"
      ],
      "metadata": {
        "id": "JQ51U9rD7nWk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***DUPLICATES IDENTIFY***"
      ],
      "metadata": {
        "id": "wnbcBW0NLtTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# duplicate values\n",
        "duplicates = data.duplicated().sum()\n",
        "print(f\"Number of duplicate rows = {duplicates}\")\n",
        "\n",
        "# drop duplicates\n",
        "print(\"After dropping duplicates\")\n",
        "data.drop_duplicates(inplace=True)\n",
        "print(f\"Number of duplicate rows = {data.duplicated().sum()}\")"
      ],
      "metadata": {
        "id": "5lTudg0lL2Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***OUTLIERS***"
      ],
      "metadata": {
        "id": "IiQmzQguMwJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot to identify outliers\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=data['Selling_Price'])\n",
        "plt.title('Boxplot of Selling Price')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ACp-aevBwAw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Outlier treatment (if necessary)\n",
        "# Example: Removing outliers in Selling Price\n",
        "Q1 = data['Selling_Price'].quantile(0.25)\n",
        "Q3 = data['Selling_Price'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "data = data[(data['Selling_Price'] >= (Q1 - 1.5 * IQR)) & (data['Selling_Price'] <= (Q3 + 1.5 * IQR))]\n",
        "Q3 = data['Selling_Price'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "data = data[(data['Selling_Price'] >= (Q1 - 1.5 * IQR)) & (data['Selling_Price'] <= (Q3 + 1.5 * IQR))]"
      ],
      "metadata": {
        "id": "rGwOJYVdwS9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***DATA PRE-PROCESSING***"
      ],
      "metadata": {
        "id": "eQAoOLh5MdRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate skewness\n",
        "skewness = data['Selling_Price'].skew()\n",
        "print(f'Skewness of Selling_Price: {skewness}')\n",
        "\n",
        "# Plot the distribution of Selling_Price\n",
        "sns.histplot(data['Selling_Price'], kde=True)\n",
        "plt.title('Distribution of Selling_Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zjLwd3Q2dh99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.hist(figsize = (12,10), bins = 50)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DGLKwlQlUL3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.dtypes)"
      ],
      "metadata": {
        "id": "49dArtlMeWpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only numerical features\n",
        "numerical_features = data.select_dtypes(include=[\"number\"])\n",
        "\n",
        "# Calculate the correlation matrix for numerical features\n",
        "correlation_matrix = numerical_features.corr()\n",
        "\n",
        "# Display the correlation matrix\n",
        "print(\"\\nCorrelation Matrix:\")\n",
        "correlation_matrix"
      ],
      "metadata": {
        "id": "UJ_g7q0hdz9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the correlation matrix using a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='Set1', fmt='.2f')\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3yEnW5Q1d7sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***VISUALISATIONS***"
      ],
      "metadata": {
        "id": "CaNpdzJ3PvUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotdata(data, col_name, col_type):\n",
        "    if col_type == 'object':\n",
        "        plt.figure(figsize=(15,3))\n",
        "        sns.countplot(x=col_name, data=data, palette='YlGnBu')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "A1XDiJcyU7b-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in data.columns:\n",
        "    print(i)\n",
        "    plotdata(data, i, data[i].dtype)"
      ],
      "metadata": {
        "id": "sHhAgDSKVAWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking relationship of Year with Price\n",
        "\n",
        "plt.subplots(figsize=(20,10))\n",
        "ax=sns.swarmplot(x='Year',y='Selling_Price',data=data) # Change 'year' to 'Year' and 'Price' to 'Selling_Price'\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=40,ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KSEPN8ZeV7R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Encoding the Categorical Columns***"
      ],
      "metadata": {
        "id": "evGUWkqfj5de"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding categorical variables\n",
        "data = pd.get_dummies(data, columns=['Fuel_Type', 'Selling_type', 'Transmission'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "pMwe0g5lht19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "qQUZRsOkbjLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***SPLITING THE DATA SET***"
      ],
      "metadata": {
        "id": "Ox4PZjPIkw9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(['Car_Name','Selling_Price'],axis=1)\n",
        "Y = data['Selling_Price']"
      ],
      "metadata": {
        "id": "yPtlS8COby5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "# Now using 'Y' instead of 'y'"
      ],
      "metadata": {
        "id": "jZ8CiXKzf7I8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Model Training & Model Evaluation***"
      ],
      "metadata": {
        "id": "L5sQ_30boFj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "URRwSD1TJTT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "ZbS0ajZOjaO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Random Forest model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "45A-IBDofO4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on the test set\n",
        "y_pred = rf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "DQvTYJqrxDKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization: Actual vs Predicted\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Actual Selling Price')\n",
        "plt.ylabel('Predicted Selling Price')\n",
        "plt.title('Actual vs Predicted Selling Price')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WjOcblUpxGqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error Rate Calculation\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R-squared: {r2}')"
      ],
      "metadata": {
        "id": "EzwTnQ99xLaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***HYPERPARAMETER TUNING***"
      ],
      "metadata": {
        "id": "tm46Tm5UliDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Ec5FRFzBxZyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "_3vljzbdxbpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-evaluate the model with best parameters\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "y_pred_best = best_rf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "wy5CnRJ4xjX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Error Rate Calculation\n",
        "\n",
        "mse_best = mean_squared_error(y_test, y_pred_best)\n",
        "r2_best = r2_score(y_test, y_pred_best)\n",
        "\n",
        "\n",
        "print(f'Best Model - Mean Squared Error: {mse_best}')\n",
        "print(f'Best Model - R-squared: {r2_best}')"
      ],
      "metadata": {
        "id": "JVe78EbDxo8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizations\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(feature_importance['feature'], feature_importance['importance'])\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Feature Importance (Random Forest)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ykwcaCH3j_UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ***Conclusion***\n",
        "In conclusion, the analysis of the car dataset revealed valuable insights into the factors influencing car selling prices, with a successful implementation of a Random Forest Regressor to predict these prices based on various features. Through exploratory data analysis, we identified and addressed outliers and missing values, leading to a cleaner dataset for modeling. The initial model performance metrics indicated room for improvement, which was achieved through hyperparameter tuning using Grid Search, resulting in enhanced accuracy and reduced error rates. Visualizations of actual versus predicted selling prices illustrated the model's effectiveness, and the overall process underscored the significance of data preprocessing, feature selection, and model evaluation in building robust predictive models. This structured approach not only provided a solid foundation for understanding the car market but also highlighted opportunities for further exploration and refinement in predictive analytics."
      ],
      "metadata": {
        "id": "O4K1_gmGju14"
      }
    }
  ]
}